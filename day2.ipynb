{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d67ff04b",
   "metadata": {},
   "source": [
    "To create your own corpora, train a word2vec model using the gensim library and then import it using the KeyedVectors.load_word2vec_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2a067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import matplotlib.pylab as plot\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.stats import spearmanr \n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166c73",
   "metadata": {},
   "source": [
    "# Load embeddings and a testset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c025cf9",
   "metadata": {},
   "source": [
    "First we load embeddings trained on the __[English Semeval dataset](https://www.ims.uni-stuttgart.de/en/research/resources/corpora/sem-eval-ulscd-eng/)__, i.e. on two subsets of the Corpus of Historical American English (COHA)\n",
    "\n",
    "`coha1` - embeddings trained on subset from 1810 to 1860\n",
    "\n",
    "`coha2` - embeddings trained on subset from 1960 to 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de47ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coha1 =  KeyedVectors.load_word2vec_format(datapath(os.getcwd() + '/embeddings/coha1_win10-k5-dim100-ep30-iter1.sgns.gz'),\n",
    "                                           binary=False) \n",
    "coha2 =  KeyedVectors.load_word2vec_format(datapath(os.getcwd() + '/embeddings/coha2_win10-k5-dim100-ep30-iter1.sgns.gz'),\n",
    "                                           binary=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8090e252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1869b7d0220>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2982834",
   "metadata": {},
   "source": [
    "The difference between corpora is reflected in difference between embeddings. Lets see, for example, how nearest neibours for word `pilot` changed over time. We can see that in the earlier corpus the word is associated with sea navigation, while in the later corpus the meaning shifted towards aircraft navigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd2e3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boat', 0.6582388281822205),\n",
       " ('ship', 0.6355108618736267),\n",
       " ('sloop', 0.5993596911430359),\n",
       " ('schooner', 0.5912287831306458),\n",
       " ('frigate', 0.5773791074752808),\n",
       " ('paddle', 0.5766931772232056),\n",
       " ('shallop', 0.575290322303772),\n",
       " ('windward', 0.5710005164146423),\n",
       " ('becalmed', 0.5668559670448303),\n",
       " ('canoe', 0.5641116499900818)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha1.similar_by_word(\"pilot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34476521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plane_nn', 0.7463921904563904),\n",
       " ('crew', 0.6648629903793335),\n",
       " ('flight', 0.6633000373840332),\n",
       " ('aircraft', 0.6505595445632935),\n",
       " ('uss', 0.649913489818573),\n",
       " ('fighter', 0.6363934278488159),\n",
       " ('helicopter', 0.6343678832054138),\n",
       " ('co-pilot', 0.6171591281890869),\n",
       " ('valujet', 0.6163130402565002),\n",
       " ('single-engine', 0.6103010773658752)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha2.similar_by_word(\"pilot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374043d2",
   "metadata": {},
   "source": [
    "**Your turn:** think about other English words that radically changed their meaning between the first half of 19th century and the second half of 20th century. Insert them into cells above to test your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "392ac312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lothario', 0.7040339112281799), ('joyous', 0.6585600972175598), ('blithely', 0.6554749608039856), ('graceful', 0.646531343460083), ('fantastically', 0.6295477151870728), ('garlanded', 0.62470942735672), ('waltze', 0.6234743595123291), ('lightsome', 0.6219693422317505), ('dance', 0.6200207471847534), ('parterre', 0.6117178797721863)]\n",
      "[('lesbian', 0.6585097312927246), ('activist', 0.6079414486885071), ('woman', 0.5512454509735107), ('bisexual', 0.5429787039756775), ('abortion', 0.5241272449493408), ('feminist', 0.5222228169441223), ('minority', 0.5057562589645386), ('homosexual', 0.4921431839466095), ('cowardice', 0.4860481321811676), ('southerner', 0.4788546562194824)]\n"
     ]
    }
   ],
   "source": [
    "print(coha1.similar_by_word(\"gay\"))\n",
    "print(coha2.similar_by_word(\"gay\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cfed6",
   "metadata": {},
   "source": [
    "You probably noted that word `plane` is presented in the embedding dictionary together with a part of speech tag `plane_nn`. This is because this word belongs to a SemEval testset. The corpus was preprocessed to use only required word forms.\n",
    "\n",
    "Lets now load the whole testset, together with manually annotated change scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1ae87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack_nn</td>\n",
       "      <td>0.143970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag_nn</td>\n",
       "      <td>0.100364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_nn</td>\n",
       "      <td>0.409367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit_nn</td>\n",
       "      <td>0.306577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chairman_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle_vb</td>\n",
       "      <td>0.171087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contemplation_nn</td>\n",
       "      <td>0.070839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donkey_nn</td>\n",
       "      <td>0.160104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edge_nn</td>\n",
       "      <td>0.260966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_nn</td>\n",
       "      <td>0.137791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fiction_nn</td>\n",
       "      <td>0.020723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gas_nn</td>\n",
       "      <td>0.159570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graft_nn</td>\n",
       "      <td>0.553976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>head_nn</td>\n",
       "      <td>0.295256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>land_nn</td>\n",
       "      <td>0.223448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lane_nn</td>\n",
       "      <td>0.103720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lass_nn</td>\n",
       "      <td>0.212590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multitude_nn</td>\n",
       "      <td>0.100364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ounce_nn</td>\n",
       "      <td>0.284899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part_nn</td>\n",
       "      <td>0.161271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pin_vb</td>\n",
       "      <td>0.207212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plane_nn</td>\n",
       "      <td>0.882348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>player_nn</td>\n",
       "      <td>0.273667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prop_nn</td>\n",
       "      <td>0.624760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>quilt_nn</td>\n",
       "      <td>0.123145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rag_nn</td>\n",
       "      <td>0.276515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>record_nn</td>\n",
       "      <td>0.427350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relationship_nn</td>\n",
       "      <td>0.056218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>risk_nn</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>savage_nn</td>\n",
       "      <td>0.096869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stab_nn</td>\n",
       "      <td>0.400590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stroke_vb</td>\n",
       "      <td>0.176231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thump_nn</td>\n",
       "      <td>0.142992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tip_vb</td>\n",
       "      <td>0.678899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tree_nn</td>\n",
       "      <td>0.070839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>twist_nn</td>\n",
       "      <td>0.398493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_nn</td>\n",
       "      <td>0.179307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     truth\n",
       "0          attack_nn  0.143970\n",
       "1             bag_nn  0.100364\n",
       "2            ball_nn  0.409367\n",
       "3             bit_nn  0.306577\n",
       "4        chairman_nn  0.000000\n",
       "5          circle_vb  0.171087\n",
       "6   contemplation_nn  0.070839\n",
       "7          donkey_nn  0.160104\n",
       "8            edge_nn  0.260966\n",
       "9            face_nn  0.137791\n",
       "10        fiction_nn  0.020723\n",
       "11            gas_nn  0.159570\n",
       "12          graft_nn  0.553976\n",
       "13           head_nn  0.295256\n",
       "14           land_nn  0.223448\n",
       "15           lane_nn  0.103720\n",
       "16           lass_nn  0.212590\n",
       "17      multitude_nn  0.100364\n",
       "18          ounce_nn  0.284899\n",
       "19           part_nn  0.161271\n",
       "20            pin_vb  0.207212\n",
       "21          plane_nn  0.882348\n",
       "22         player_nn  0.273667\n",
       "23           prop_nn  0.624760\n",
       "24          quilt_nn  0.123145\n",
       "25            rag_nn  0.276515\n",
       "26         record_nn  0.427350\n",
       "27   relationship_nn  0.056218\n",
       "28           risk_nn  0.000000\n",
       "29         savage_nn  0.096869\n",
       "30           stab_nn  0.400590\n",
       "31         stroke_vb  0.176231\n",
       "32          thump_nn  0.142992\n",
       "33            tip_vb  0.678899\n",
       "34           tree_nn  0.070839\n",
       "35          twist_nn  0.398493\n",
       "36           word_nn  0.179307"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded = pd.read_csv(os.getcwd() + '/targets/english/graded.txt', sep=\"\\t\", header=None, names=['word', 'truth'])\n",
    "graded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfccf987",
   "metadata": {},
   "source": [
    "# Jaccard distance\n",
    "This method is based on computing Jaccard distance between sets of 10 nearest neighbors of x\n",
    "(by cosine distance) in A and B. The Jaccard distance is computed as a intersection size divided by the union size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c51fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition\n",
    "\n",
    "def jaccard(word, emb1 = coha1, emb2 = coha2, nn = 500):\n",
    "    # retrieve nearest neighbors\n",
    "    nn1 = emb1.similar_by_word(word, nn)\n",
    "    nn2 = emb2.similar_by_word(word, nn)\n",
    "    \n",
    "    # this method does not use similarity scores, only lists of words\n",
    "    nn1 = set(n[0] for n in nn1)\n",
    "    nn2 = set(n[0] for n in nn2)\n",
    "    \n",
    "    # compute Jaccard score\n",
    "    jaccard = len(nn1.intersection(nn2)) / len(nn1.union(nn2))\n",
    "    \n",
    "    # in the Semeval dataset change scores are between 0 and 1\n",
    "    # so that 0 means no change, 1 means the highest change\n",
    "    # Jaccard score is reverse, 0 means the smallest overlap, i.e. the strongest change\n",
    "    # thus we return 1 - jaccard as the final change score\n",
    "    \n",
    "    return 1 - jaccard\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e22c5fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>truth</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>glob_a</th>\n",
       "      <th>align_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack_nn</td>\n",
       "      <td>0.143970</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.288913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.296581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_nn</td>\n",
       "      <td>0.409367</td>\n",
       "      <td>0.961578</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.335226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit_nn</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.324374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chairman_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.403582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle_vb</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.394965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contemplation_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.438667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donkey_nn</td>\n",
       "      <td>0.160104</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.438732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edge_nn</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.349858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_nn</td>\n",
       "      <td>0.137791</td>\n",
       "      <td>0.885173</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.114934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fiction_nn</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.357563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gas_nn</td>\n",
       "      <td>0.159570</td>\n",
       "      <td>0.928189</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.457652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graft_nn</td>\n",
       "      <td>0.553976</td>\n",
       "      <td>0.993964</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.595382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>head_nn</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>land_nn</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.191293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lane_nn</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>0.935037</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.350338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lass_nn</td>\n",
       "      <td>0.212590</td>\n",
       "      <td>0.962656</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.557831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multitude_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>0.972251</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.443918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ounce_nn</td>\n",
       "      <td>0.284899</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.307376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part_nn</td>\n",
       "      <td>0.161271</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.276895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pin_vb</td>\n",
       "      <td>0.207212</td>\n",
       "      <td>0.935037</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.410849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plane_nn</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.717618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>player_nn</td>\n",
       "      <td>0.273667</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.425634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prop_nn</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>0.978550</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.540134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>quilt_nn</td>\n",
       "      <td>0.123145</td>\n",
       "      <td>0.932764</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.403513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rag_nn</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.911861</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.367795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>record_nn</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.971193</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.471894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relationship_nn</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.428085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>risk_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>savage_nn</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>0.957247</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.468566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stab_nn</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>0.959417</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stroke_vb</td>\n",
       "      <td>0.176231</td>\n",
       "      <td>0.916576</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.420754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thump_nn</td>\n",
       "      <td>0.142992</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.448841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tip_vb</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.968008</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.521430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tree_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.834499</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.133642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>twist_nn</td>\n",
       "      <td>0.398493</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.492496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_nn</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.899890</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.196563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     truth   jaccard    glob_a  align_cos\n",
       "0          attack_nn  0.143970  0.953975  0.009574   0.288913\n",
       "1             bag_nn  0.100364  0.918919  0.009409   0.296581\n",
       "2            ball_nn  0.409367  0.961578  0.009782   0.335226\n",
       "3             bit_nn  0.306577  0.944034  0.010931   0.324374\n",
       "4        chairman_nn  0.000000  0.970134  0.011066   0.403582\n",
       "5          circle_vb  0.171087  0.945148  0.009862   0.394965\n",
       "6   contemplation_nn  0.070839  0.925886  0.009587   0.438667\n",
       "7          donkey_nn  0.160104  0.936170  0.009891   0.438732\n",
       "8            edge_nn  0.260966  0.929336  0.009651   0.349858\n",
       "9            face_nn  0.137791  0.885173  0.009190   0.114934\n",
       "10        fiction_nn  0.020723  0.929336  0.010363   0.357563\n",
       "11            gas_nn  0.159570  0.928189  0.009783   0.457652\n",
       "12          graft_nn  0.553976  0.993964  0.012233   0.595382\n",
       "13           head_nn  0.295256  0.901099  0.008403   0.219520\n",
       "14           land_nn  0.223448  0.918919  0.009599   0.191293\n",
       "15           lane_nn  0.103720  0.935037  0.008966   0.350338\n",
       "16           lass_nn  0.212590  0.962656  0.010887   0.557831\n",
       "17      multitude_nn  0.100364  0.972251  0.009305   0.443918\n",
       "18          ounce_nn  0.284899  0.913043  0.008718   0.307376\n",
       "19           part_nn  0.161271  0.945148  0.008692   0.276895\n",
       "20            pin_vb  0.207212  0.935037  0.008927   0.410849\n",
       "21          plane_nn  0.882348  0.989899  0.012611   0.717618\n",
       "22         player_nn  0.273667  0.980632  0.010202   0.425634\n",
       "23           prop_nn  0.624760  0.978550  0.010469   0.540134\n",
       "24          quilt_nn  0.123145  0.932764  0.009591   0.403513\n",
       "25            rag_nn  0.276515  0.911861  0.009213   0.367795\n",
       "26         record_nn  0.427350  0.971193  0.010699   0.471894\n",
       "27   relationship_nn  0.056218  0.953975  0.010114   0.428085\n",
       "28           risk_nn  0.000000  0.958333  0.009980   0.417910\n",
       "29         savage_nn  0.096869  0.957247  0.012386   0.468566\n",
       "30           stab_nn  0.400590  0.959417  0.010065   0.514487\n",
       "31         stroke_vb  0.176231  0.916576  0.008913   0.420754\n",
       "32          thump_nn  0.142992  0.915401  0.010164   0.448841\n",
       "33            tip_vb  0.678899  0.968008  0.009395   0.521430\n",
       "34           tree_nn  0.070839  0.834499  0.009647   0.133642\n",
       "35          twist_nn  0.398493  0.975410  0.010912   0.492496\n",
       "36           word_nn  0.179307  0.899890  0.009151   0.196563"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute for each word in the list\n",
    "graded[\"jaccard\"] = graded.apply(lambda row: jaccard(row.word), axis = 1)\n",
    "graded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948acc33",
   "metadata": {},
   "source": [
    "Spearman Rank Correlation: we do not look at the values for each word, but take all the words and 1) rank them based on truth values, and 2) based on Jaccard values. Then calculate how many words are in the same rank in both lists (how many words correlate in their ranks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b578165c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.3420896608497632, pvalue=0.03822631988356302)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using Spearman Rank Correlation\n",
    "spearmanr(graded.truth, graded.jaccard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6927479",
   "metadata": {},
   "source": [
    "It is good to experiment with different numbers of nearest neighbors and calculate spearman rank correlation each time to see whether we can find the value that provides the highest correlation. But at the same time, this can lead to overfitting to this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2b6f8",
   "metadata": {},
   "source": [
    "**Your turn:** Explore whether another number of nearest neighbors (smaller or greater than 10) would improve the method results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda74e7b",
   "metadata": {},
   "source": [
    "# Global Anchors\n",
    "Here, the intersection of A and B\n",
    "vocabularies (‘global anchors’, or VAB) is used. The degree of semantic\n",
    "change is defined as the cosine distance between the vector of the cosine\n",
    "similarities of x embedding in A to all words in VAB and the vector of the\n",
    "cosine similarities of x embedding in B to all words in VAB;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f018df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69317734, 0.70348793, 0.7943801 , 0.83782107, 0.9644142 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate cosine distance between a word and other words\n",
    "coha2.distances(\"plane\", [\"fly\", \"boat\", \"pilot\", \"cat\", \"academic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9439d527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['murphy',\n",
       " 'crony',\n",
       " 'vigilant',\n",
       " 'complex',\n",
       " 'cheapen',\n",
       " 'hume',\n",
       " 'proportionately',\n",
       " 'malaria',\n",
       " 'prerogative',\n",
       " 'assimilate',\n",
       " 'technical',\n",
       " 'fatally',\n",
       " 'esau',\n",
       " 'dangerously',\n",
       " 'shade',\n",
       " 'my',\n",
       " 'xiii',\n",
       " 'wench',\n",
       " 'bodkin',\n",
       " 'vengeance',\n",
       " '+',\n",
       " 'footstep',\n",
       " 'enquire',\n",
       " 'venerate',\n",
       " 'incas',\n",
       " 'butterfly',\n",
       " 'flit',\n",
       " 'eradicate',\n",
       " 'distinguished',\n",
       " 'diffidence',\n",
       " 'compete',\n",
       " 'lengthen',\n",
       " 'immensity',\n",
       " 'matty',\n",
       " 'melee',\n",
       " 'mountainous',\n",
       " \"e'en\",\n",
       " 'drawer',\n",
       " 'provincial',\n",
       " 'build',\n",
       " 'correspondence',\n",
       " 'excellency',\n",
       " 'hercules',\n",
       " 'plaint',\n",
       " 'violence',\n",
       " 'embarrassment',\n",
       " 'rack',\n",
       " 'mademoiselle',\n",
       " 'amplitude',\n",
       " 'refract',\n",
       " 'particular',\n",
       " 'inure',\n",
       " 'eda',\n",
       " 'multitude_nn',\n",
       " 'fourth',\n",
       " 'emphatic',\n",
       " 'fin',\n",
       " 'dogma',\n",
       " 'greenland',\n",
       " 'carouse',\n",
       " 'attraction',\n",
       " 'squirrel',\n",
       " 'attractiveness',\n",
       " 'idiotic',\n",
       " 'girlish',\n",
       " 'neighbor',\n",
       " 'awhile',\n",
       " 'goose',\n",
       " 'mercifully',\n",
       " 'buy',\n",
       " 'imitate',\n",
       " 'placard',\n",
       " 'warlike',\n",
       " 'shoreward',\n",
       " 'tri',\n",
       " 'tempting',\n",
       " 'undisturbed',\n",
       " 'cavity',\n",
       " 'sultan',\n",
       " 'spoonful',\n",
       " 'disc',\n",
       " 'boast',\n",
       " 'cheshire',\n",
       " 'discrimination',\n",
       " 'banner',\n",
       " 'topaz',\n",
       " 'devotee',\n",
       " 'god',\n",
       " 'dispassionate',\n",
       " 'compose',\n",
       " 'kean',\n",
       " 'flowery',\n",
       " '204',\n",
       " 'spinal',\n",
       " 'mat',\n",
       " 'framed',\n",
       " 'luxembourg',\n",
       " 'mid-',\n",
       " 'entrap',\n",
       " 'video']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAB = list(set(coha1.index_to_key).intersection(coha2.index_to_key))\n",
    "\n",
    "VAB[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "837c9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition\n",
    "def glob_a(word, emb1 = coha1, emb2 = coha2):\n",
    "    \n",
    "    # intersection of two vocabularies\n",
    "    VAB_all = list(set(emb1.index_to_key).intersection(emb2.index_to_key))\n",
    "    VAB = [\"yellow\", \"white\", \"blue\", \"black\", \"sun\", \"cat\", \"and\", \"in\", \"comma\", \"while\", \"because\",\n",
    "                    \"number\", \"word\", \"human\", \"animal\", \"water\", \"air\"]\n",
    "    \n",
    "    # vectors of cosine similarities\n",
    "    v1 = emb1.distances(word, VAB)\n",
    "    v2 = emb2.distances(word, VAB)\n",
    "    \n",
    "    # second-order cosine distance\n",
    "    return float(cosine(v1, v2))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3a8b33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>truth</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>glob_a</th>\n",
       "      <th>align_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack_nn</td>\n",
       "      <td>0.143970</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.288913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.296581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_nn</td>\n",
       "      <td>0.409367</td>\n",
       "      <td>0.961578</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.335226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit_nn</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>0.324374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chairman_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.403582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle_vb</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.394965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contemplation_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.925886</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.438667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donkey_nn</td>\n",
       "      <td>0.160104</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.438732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edge_nn</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.349858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_nn</td>\n",
       "      <td>0.137791</td>\n",
       "      <td>0.885173</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.114934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fiction_nn</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.357563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gas_nn</td>\n",
       "      <td>0.159570</td>\n",
       "      <td>0.928189</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.457652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graft_nn</td>\n",
       "      <td>0.553976</td>\n",
       "      <td>0.993964</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.595382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>head_nn</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>0.901099</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>land_nn</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.191293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lane_nn</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>0.935037</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.350338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lass_nn</td>\n",
       "      <td>0.212590</td>\n",
       "      <td>0.962656</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.557831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multitude_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>0.972251</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.443918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ounce_nn</td>\n",
       "      <td>0.284899</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.307376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part_nn</td>\n",
       "      <td>0.161271</td>\n",
       "      <td>0.945148</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.276895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pin_vb</td>\n",
       "      <td>0.207212</td>\n",
       "      <td>0.935037</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.410849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plane_nn</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.717618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>player_nn</td>\n",
       "      <td>0.273667</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.425634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prop_nn</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>0.978550</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.540134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>quilt_nn</td>\n",
       "      <td>0.123145</td>\n",
       "      <td>0.932764</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.403513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rag_nn</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.911861</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.367795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>record_nn</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>0.971193</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.471894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relationship_nn</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.953975</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.428085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>risk_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>savage_nn</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>0.957247</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.468566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stab_nn</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>0.959417</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stroke_vb</td>\n",
       "      <td>0.176231</td>\n",
       "      <td>0.916576</td>\n",
       "      <td>0.010644</td>\n",
       "      <td>0.420754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thump_nn</td>\n",
       "      <td>0.142992</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.448841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tip_vb</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.968008</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.521430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tree_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.834499</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.133642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>twist_nn</td>\n",
       "      <td>0.398493</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.492496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_nn</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.899890</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.196563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     truth   jaccard    glob_a  align_cos\n",
       "0          attack_nn  0.143970  0.953975  0.004776   0.288913\n",
       "1             bag_nn  0.100364  0.918919  0.003445   0.296581\n",
       "2            ball_nn  0.409367  0.961578  0.005995   0.335226\n",
       "3             bit_nn  0.306577  0.944034  0.007861   0.324374\n",
       "4        chairman_nn  0.000000  0.970134  0.004871   0.403582\n",
       "5          circle_vb  0.171087  0.945148  0.006412   0.394965\n",
       "6   contemplation_nn  0.070839  0.925886  0.002523   0.438667\n",
       "7          donkey_nn  0.160104  0.936170  0.005262   0.438732\n",
       "8            edge_nn  0.260966  0.929336  0.008800   0.349858\n",
       "9            face_nn  0.137791  0.885173  0.010834   0.114934\n",
       "10        fiction_nn  0.020723  0.929336  0.003031   0.357563\n",
       "11            gas_nn  0.159570  0.928189  0.006517   0.457652\n",
       "12          graft_nn  0.553976  0.993964  0.008074   0.595382\n",
       "13           head_nn  0.295256  0.901099  0.006435   0.219520\n",
       "14           land_nn  0.223448  0.918919  0.010744   0.191293\n",
       "15           lane_nn  0.103720  0.935037  0.004139   0.350338\n",
       "16           lass_nn  0.212590  0.962656  0.003695   0.557831\n",
       "17      multitude_nn  0.100364  0.972251  0.008145   0.443918\n",
       "18          ounce_nn  0.284899  0.913043  0.005135   0.307376\n",
       "19           part_nn  0.161271  0.945148  0.006050   0.276895\n",
       "20            pin_vb  0.207212  0.935037  0.004692   0.410849\n",
       "21          plane_nn  0.882348  0.989899  0.012958   0.717618\n",
       "22         player_nn  0.273667  0.980632  0.005249   0.425634\n",
       "23           prop_nn  0.624760  0.978550  0.005522   0.540134\n",
       "24          quilt_nn  0.123145  0.932764  0.005459   0.403513\n",
       "25            rag_nn  0.276515  0.911861  0.005676   0.367795\n",
       "26         record_nn  0.427350  0.971193  0.006525   0.471894\n",
       "27   relationship_nn  0.056218  0.953975  0.007365   0.428085\n",
       "28           risk_nn  0.000000  0.958333  0.004321   0.417910\n",
       "29         savage_nn  0.096869  0.957247  0.006941   0.468566\n",
       "30           stab_nn  0.400590  0.959417  0.003684   0.514487\n",
       "31         stroke_vb  0.176231  0.916576  0.010644   0.420754\n",
       "32          thump_nn  0.142992  0.915401  0.008151   0.448841\n",
       "33            tip_vb  0.678899  0.968008  0.006204   0.521430\n",
       "34           tree_nn  0.070839  0.834499  0.003778   0.133642\n",
       "35          twist_nn  0.398493  0.975410  0.006724   0.492496\n",
       "36           word_nn  0.179307  0.899890  0.003087   0.196563"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute for each word in the list\n",
    "graded[\"glob_a\"] = graded.apply(lambda row: glob_a(row.word), axis = 1)\n",
    "graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b453b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.31394866819310113, pvalue=0.058452748571904974)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using Spearman Rank Correlation\n",
    "spearmanr(graded.truth, graded.glob_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90a673",
   "metadata": {},
   "source": [
    "**Your turn:** Why, do you think, the correlation is so low in this case? Would it be possible to improve the method by curating VAB? We could improve the method by choosing a specific set of words as global anchors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1fbb9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Orthogonal alignment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ca9dd",
   "metadata": {},
   "source": [
    "In the methods above we used word embeddings only indirectly, by computing distances to other words within the same embedding space. This is because embeddings are trained independently and, due to stochastic nature of the training process, are not aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f32eb1",
   "metadata": {},
   "source": [
    "Foe example, nearest neighbors for word 'cloud' are rather similar in `coha1` and `coha2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11063387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mist', 0.765891432762146),\n",
       " ('sky', 0.7651017308235168),\n",
       " ('storm-clouds', 0.7596777677536011),\n",
       " ('fleecy', 0.7539883852005005),\n",
       " ('haze', 0.7314548492431641),\n",
       " ('lurid', 0.7162288427352905),\n",
       " ('darkness', 0.7080817222595215),\n",
       " ('gloom', 0.7058361172676086),\n",
       " ('fleck', 0.7058289051055908),\n",
       " ('sunlight', 0.7039923071861267)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha1.similar_by_word('cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a16c4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sky', 0.7951599359512329),\n",
       " ('haze', 0.7400579452514648),\n",
       " ('fog', 0.7182807922363281),\n",
       " ('billows', 0.7130799889564514),\n",
       " ('fleecy', 0.7010570168495178),\n",
       " ('mist', 0.6893543601036072),\n",
       " ('wind-blown', 0.6866617202758789),\n",
       " ('blue-white', 0.6845375299453735),\n",
       " ('dust', 0.683636486530304),\n",
       " ('sunlight', 0.6821059584617615)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha2.similar_by_word('cloud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31059584",
   "metadata": {},
   "source": [
    "However, if we take a *vector* for this word from the first embedding space and try to find where it is located in the second embedding space, the nearest words look completely irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4d5fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aid', 0.3376768231391907),\n",
       " ('pare', 0.3343074917793274),\n",
       " ('grueling', 0.3235573470592499),\n",
       " ('disciplined', 0.3160246014595032),\n",
       " ('reimburse', 0.3157447874546051),\n",
       " ('th', 0.30689093470573425),\n",
       " ('reduction', 0.30620092153549194),\n",
       " ('cooperation', 0.30567219853401184),\n",
       " ('iou', 0.3046630620956421),\n",
       " ('screener', 0.30425143241882324)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coha2.similar_by_vector(coha1['cloud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7186a31",
   "metadata": {},
   "source": [
    "Thus, we need to first *align* embedding spaces so that position of semantically similar words become close across embedding space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9ba2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment is done using vocabulary intersection\n",
    "VAB = list(set(coha1.index_to_key).intersection(coha2.index_to_key))\n",
    "vectors1=coha1.vectors_for_all(VAB).vectors\n",
    "vectors2=coha2.vectors_for_all(VAB).vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd52b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication\n",
    "m = vectors2.T.dot(vectors1)\n",
    "# SVD decomposition\n",
    "u, _, v = np.linalg.svd(m)\n",
    "# Orthogonal transformation of the second matrix that makes it most similar to the first matrix\n",
    "ortho = u.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a4f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming embedding space using the orthogonal matrix\n",
    "coha2.vectors = coha2.vectors.dot(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7249aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cloud', 0.8158999085426331),\n",
       " ('sky', 0.752348780632019),\n",
       " ('fleecy', 0.701219916343689),\n",
       " ('mist', 0.6952263116836548),\n",
       " ('sun', 0.690657913684845),\n",
       " ('haze', 0.6738666892051697),\n",
       " ('whitely', 0.6718099117279053),\n",
       " ('wind-blown', 0.6650335788726807),\n",
       " ('gloom', 0.6592667102813721),\n",
       " ('blaze', 0.6576600670814514)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that now we can query coha2 embeddings using vectors from coha1 embedding space\n",
    "coha2.similar_by_vector(coha1['cloud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ffae7",
   "metadata": {},
   "source": [
    "Now we can measure the degree of semantic change directly using cosine similarities between vectors from `coha1` and `coha2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b05e0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>truth</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>glob_a</th>\n",
       "      <th>align_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack_nn</td>\n",
       "      <td>0.143970</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.288913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.296581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_nn</td>\n",
       "      <td>0.409367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.335226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit_nn</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.324374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chairman_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.403582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle_vb</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.394965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contemplation_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.438667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donkey_nn</td>\n",
       "      <td>0.160104</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.438732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edge_nn</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.349858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_nn</td>\n",
       "      <td>0.137791</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.114934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fiction_nn</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.357563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gas_nn</td>\n",
       "      <td>0.159570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.457652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graft_nn</td>\n",
       "      <td>0.553976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.595382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>head_nn</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>land_nn</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.191293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lane_nn</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.350338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lass_nn</td>\n",
       "      <td>0.212590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.557831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multitude_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.443918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ounce_nn</td>\n",
       "      <td>0.284899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.307376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part_nn</td>\n",
       "      <td>0.161271</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.276895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pin_vb</td>\n",
       "      <td>0.207212</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.410849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plane_nn</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.717618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>player_nn</td>\n",
       "      <td>0.273667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.425634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prop_nn</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.540134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>quilt_nn</td>\n",
       "      <td>0.123145</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.403513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rag_nn</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.367795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>record_nn</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.471894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relationship_nn</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.428085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>risk_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>savage_nn</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.468566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stab_nn</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stroke_vb</td>\n",
       "      <td>0.176231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.420754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thump_nn</td>\n",
       "      <td>0.142992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.448841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tip_vb</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.521430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tree_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.133642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>twist_nn</td>\n",
       "      <td>0.398493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.492496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_nn</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.196563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     truth   jaccard    glob_a  align_cos\n",
       "0          attack_nn  0.143970  0.888889  0.009574   0.288913\n",
       "1             bag_nn  0.100364  1.000000  0.009409   0.296581\n",
       "2            ball_nn  0.409367  1.000000  0.009782   0.335226\n",
       "3             bit_nn  0.306577  0.888889  0.010931   0.324374\n",
       "4        chairman_nn  0.000000  0.888889  0.011066   0.403582\n",
       "5          circle_vb  0.171087  1.000000  0.009862   0.394965\n",
       "6   contemplation_nn  0.070839  1.000000  0.009587   0.438667\n",
       "7          donkey_nn  0.160104  0.888889  0.009891   0.438732\n",
       "8            edge_nn  0.260966  0.888889  0.009651   0.349858\n",
       "9            face_nn  0.137791  0.750000  0.009190   0.114934\n",
       "10        fiction_nn  0.020723  1.000000  0.010363   0.357563\n",
       "11            gas_nn  0.159570  1.000000  0.009783   0.457652\n",
       "12          graft_nn  0.553976  1.000000  0.012233   0.595382\n",
       "13           head_nn  0.295256  0.888889  0.008403   0.219520\n",
       "14           land_nn  0.223448  1.000000  0.009599   0.191293\n",
       "15           lane_nn  0.103720  0.888889  0.008966   0.350338\n",
       "16           lass_nn  0.212590  1.000000  0.010887   0.557831\n",
       "17      multitude_nn  0.100364  1.000000  0.009305   0.443918\n",
       "18          ounce_nn  0.284899  1.000000  0.008718   0.307376\n",
       "19           part_nn  0.161271  0.888889  0.008692   0.276895\n",
       "20            pin_vb  0.207212  0.888889  0.008927   0.410849\n",
       "21          plane_nn  0.882348  1.000000  0.012611   0.717618\n",
       "22         player_nn  0.273667  1.000000  0.010202   0.425634\n",
       "23           prop_nn  0.624760  1.000000  0.010469   0.540134\n",
       "24          quilt_nn  0.123145  0.888889  0.009591   0.403513\n",
       "25            rag_nn  0.276515  0.888889  0.009213   0.367795\n",
       "26         record_nn  0.427350  1.000000  0.010699   0.471894\n",
       "27   relationship_nn  0.056218  0.750000  0.010114   0.428085\n",
       "28           risk_nn  0.000000  1.000000  0.009980   0.417910\n",
       "29         savage_nn  0.096869  1.000000  0.012386   0.468566\n",
       "30           stab_nn  0.400590  1.000000  0.010065   0.514487\n",
       "31         stroke_vb  0.176231  1.000000  0.008913   0.420754\n",
       "32          thump_nn  0.142992  1.000000  0.010164   0.448841\n",
       "33            tip_vb  0.678899  1.000000  0.009395   0.521430\n",
       "34           tree_nn  0.070839  0.888889  0.009647   0.133642\n",
       "35          twist_nn  0.398493  1.000000  0.010912   0.492496\n",
       "36           word_nn  0.179307  0.571429  0.009151   0.196563"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded[\"align_cos\"] = graded.apply(lambda row: cosine(coha1[row.word], coha2[row.word]), axis = 1)\n",
    "graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b797383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>truth</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>glob_a</th>\n",
       "      <th>align_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plane_nn</td>\n",
       "      <td>0.882348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012611</td>\n",
       "      <td>0.717618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tip_vb</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.521430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prop_nn</td>\n",
       "      <td>0.624760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010469</td>\n",
       "      <td>0.540134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graft_nn</td>\n",
       "      <td>0.553976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.595382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>record_nn</td>\n",
       "      <td>0.427350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.471894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball_nn</td>\n",
       "      <td>0.409367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.335226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stab_nn</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.514487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>twist_nn</td>\n",
       "      <td>0.398493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010912</td>\n",
       "      <td>0.492496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bit_nn</td>\n",
       "      <td>0.306577</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.324374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>head_nn</td>\n",
       "      <td>0.295256</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ounce_nn</td>\n",
       "      <td>0.284899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008718</td>\n",
       "      <td>0.307376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rag_nn</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009213</td>\n",
       "      <td>0.367795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>player_nn</td>\n",
       "      <td>0.273667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010202</td>\n",
       "      <td>0.425634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>edge_nn</td>\n",
       "      <td>0.260966</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.349858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>land_nn</td>\n",
       "      <td>0.223448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.191293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lass_nn</td>\n",
       "      <td>0.212590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.557831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pin_vb</td>\n",
       "      <td>0.207212</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.410849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>word_nn</td>\n",
       "      <td>0.179307</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.196563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>stroke_vb</td>\n",
       "      <td>0.176231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>0.420754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>circle_vb</td>\n",
       "      <td>0.171087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.394965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part_nn</td>\n",
       "      <td>0.161271</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.276895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donkey_nn</td>\n",
       "      <td>0.160104</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.438732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gas_nn</td>\n",
       "      <td>0.159570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.457652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack_nn</td>\n",
       "      <td>0.143970</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.288913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>thump_nn</td>\n",
       "      <td>0.142992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.448841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>face_nn</td>\n",
       "      <td>0.137791</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.114934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>quilt_nn</td>\n",
       "      <td>0.123145</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.403513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lane_nn</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.350338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bag_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.296581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>multitude_nn</td>\n",
       "      <td>0.100364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009305</td>\n",
       "      <td>0.443918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>savage_nn</td>\n",
       "      <td>0.096869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012386</td>\n",
       "      <td>0.468566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contemplation_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.438667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tree_nn</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.133642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relationship_nn</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.428085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fiction_nn</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.357563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>risk_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.417910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chairman_nn</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.403582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word     truth   jaccard    glob_a  align_cos\n",
       "21          plane_nn  0.882348  1.000000  0.012611   0.717618\n",
       "33            tip_vb  0.678899  1.000000  0.009395   0.521430\n",
       "23           prop_nn  0.624760  1.000000  0.010469   0.540134\n",
       "12          graft_nn  0.553976  1.000000  0.012233   0.595382\n",
       "26         record_nn  0.427350  1.000000  0.010699   0.471894\n",
       "2            ball_nn  0.409367  1.000000  0.009782   0.335226\n",
       "30           stab_nn  0.400590  1.000000  0.010065   0.514487\n",
       "35          twist_nn  0.398493  1.000000  0.010912   0.492496\n",
       "3             bit_nn  0.306577  0.888889  0.010931   0.324374\n",
       "13           head_nn  0.295256  0.888889  0.008403   0.219520\n",
       "18          ounce_nn  0.284899  1.000000  0.008718   0.307376\n",
       "25            rag_nn  0.276515  0.888889  0.009213   0.367795\n",
       "22         player_nn  0.273667  1.000000  0.010202   0.425634\n",
       "8            edge_nn  0.260966  0.888889  0.009651   0.349858\n",
       "14           land_nn  0.223448  1.000000  0.009599   0.191293\n",
       "16           lass_nn  0.212590  1.000000  0.010887   0.557831\n",
       "20            pin_vb  0.207212  0.888889  0.008927   0.410849\n",
       "36           word_nn  0.179307  0.571429  0.009151   0.196563\n",
       "31         stroke_vb  0.176231  1.000000  0.008913   0.420754\n",
       "5          circle_vb  0.171087  1.000000  0.009862   0.394965\n",
       "19           part_nn  0.161271  0.888889  0.008692   0.276895\n",
       "7          donkey_nn  0.160104  0.888889  0.009891   0.438732\n",
       "11            gas_nn  0.159570  1.000000  0.009783   0.457652\n",
       "0          attack_nn  0.143970  0.888889  0.009574   0.288913\n",
       "32          thump_nn  0.142992  1.000000  0.010164   0.448841\n",
       "9            face_nn  0.137791  0.750000  0.009190   0.114934\n",
       "24          quilt_nn  0.123145  0.888889  0.009591   0.403513\n",
       "15           lane_nn  0.103720  0.888889  0.008966   0.350338\n",
       "1             bag_nn  0.100364  1.000000  0.009409   0.296581\n",
       "17      multitude_nn  0.100364  1.000000  0.009305   0.443918\n",
       "29         savage_nn  0.096869  1.000000  0.012386   0.468566\n",
       "6   contemplation_nn  0.070839  1.000000  0.009587   0.438667\n",
       "34           tree_nn  0.070839  0.888889  0.009647   0.133642\n",
       "27   relationship_nn  0.056218  0.750000  0.010114   0.428085\n",
       "10        fiction_nn  0.020723  1.000000  0.010363   0.357563\n",
       "28           risk_nn  0.000000  1.000000  0.009980   0.417910\n",
       "4        chairman_nn  0.000000  0.888889  0.011066   0.403582"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded.sort_values(by=\"truth\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a58d6a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.31062896928471484, pvalue=0.061314778774512406)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(graded.truth, graded.align_cos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e4deb",
   "metadata": {},
   "source": [
    "**Your turn**: now we have results from 3 different methods. Are outputs of these methods correlated? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8ca99",
   "metadata": {},
   "source": [
    "# Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c483781",
   "metadata": {},
   "source": [
    "Vizualizattion is useful for error analysis, to quickly grasp *what* changed over time. \n",
    "In this section we project multidimentional embeddings in two dimensions and use nearest neibours to see how word meaning changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55f3cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualization function\n",
    "\n",
    "def vizualize(word, emb1 = coha1, emb2 = coha2, nn = 10):\n",
    "    # get nearest neibours\n",
    "    words1 = [t[0] for t in emb1.similar_by_word(word, nn)]\n",
    "    words2 = [t[0] for t in emb2.similar_by_word(word, nn)]\n",
    "    \n",
    "    # the query word is vizualized twice, for each time period\n",
    "    # we use _the aligned_ models, which means all vectors are in the same space\n",
    "    vectors = [emb1[word], emb2[word]] + [emb1[w] for w in words1] + [emb2[w] for w in words2]\n",
    "    \n",
    "    # project vectors into two-dimensional space    \n",
    "    perplexity = int(len(vectors) ** 0.5)\n",
    "    embedding = TSNE(n_components=2, random_state=0, learning_rate=150, init=\"pca\",\n",
    "                     perplexity=perplexity)\n",
    "    # obtain coordinates for each vector in the new space\n",
    "    coordinates = embedding.fit_transform(np.array(vectors))\n",
    "    x_coordinates, y_coordinates = coordinates[:,0], coordinates[:,1]\n",
    "    \n",
    "    # plot vectors\n",
    "    plot.figure(figsize=(12, 8))\n",
    "    plot.scatter(x_coordinates, y_coordinates)\n",
    "    plot.axis(\"off\")\n",
    "    \n",
    "    # query-word coordinates\n",
    "    q_x_coordinates, q_y_coordinates = x_coordinates[:2], y_coordinates[:2]\n",
    "    \n",
    "    # label the query word with bold font\n",
    "    for label, x, y in list(zip([word, word], q_x_coordinates, q_y_coordinates)):\n",
    "        plot.annotate(label,\n",
    "                      xy=(x, y), \n",
    "                      weight=\"bold\", xytext=(-len(label) * 4.5, 4),\n",
    "                      fontsize=12, textcoords=\"offset points\")\n",
    "    \n",
    "    if q_x_coordinates[0] > q_x_coordinates[1]:\n",
    "        direction = \"<|-\"\n",
    "    else:\n",
    "        direction = \"-|>\"\n",
    "    # connect the query word with an arrow to show a direction from emb1 to emb2\n",
    "    plot.annotate(\n",
    "            \"\",\n",
    "            # arrow start\n",
    "            xy=(q_x_coordinates[0], q_y_coordinates[0]),\n",
    "            weight=\"bold\",\n",
    "            # arrow end\n",
    "            xytext=(q_x_coordinates[1], q_y_coordinates[1]),\n",
    "            arrowprops=dict(arrowstyle=direction, color=\"indianred\"),\n",
    "    )\n",
    "    \n",
    "    # label all other words\n",
    "    for label, x, y in list(zip(words1+words2, x_coordinates[2:], y_coordinates[2:])):\n",
    "        plot.annotate(label, \n",
    "                      xy=(x, y), xytext=(-len(label) * 4.5, 4),\n",
    "                      textcoords=\"offset points\")\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "539a5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "y = vizualize('gay')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8c988",
   "metadata": {},
   "source": [
    "**Your turn**: find the most and the least changed words from the SemEval list. Can you see the difference between their trajectories?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
